########################################
# Cluster manager
# Using local[*] for macOS compatibility (YARN has SASL/RPC issues).
# Spark still uses HDFS for storage and Hive metastore for catalog.
########################################
spark.master                      local[*]
spark.submit.deployMode           client

########################################
# Application identity
########################################
spark.app.name                    local-data-platform-hdfs

########################################
# Resource tuning (local dev friendly)
########################################
spark.driver.memory               5g

########################################
# Hadoop / HDFS integration
########################################
spark.hadoop.fs.defaultFS         hdfs://localhost:8020

########################################
# Hive integration
########################################
spark.sql.catalogImplementation   hive
spark.sql.warehouse.dir           /user/hive/warehouse

########################################
# Event logging (YARN + HDFS)
########################################
spark.eventLog.enabled            true
spark.eventLog.dir                hdfs:///spark-history

########################################
# SQL & Parquet defaults
########################################
spark.sql.shuffle.partitions      8
spark.sql.adaptive.enabled        true
spark.sql.parquet.compression.codec snappy

########################################
# Serialization (safe default)
########################################
spark.serializer                  org.apache.spark.serializer.KryoSerializer